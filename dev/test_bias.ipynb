{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('dacy': venv)"
  },
  "interpreter": {
   "hash": "69f6eb96a37a43867553731f8edb0a55a5852b5c9c304e04d7bd7872e5b1c11d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Augmentation\n",
    "This notebook recreates Table X from the paper XX and illustrates how to use the augmenters and scoring functions included in DaCy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dacy\n",
    "from dacy.augmenters import create_pers_augmenter, create_keyboard_augmenter, create_æøå_augmenter\n",
    "from dacy.datasets import danish_names, muslim_names\n",
    "from dacy.score import score, n_sents_score\n",
    "\n",
    "import spacy\n",
    "from spacy.training.augment import create_lower_casing_augmenter, dont_augment\n",
    "\n",
    "from typing import Callable, List\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "source": [
    "Start off by loading the test set and defining a function that applies the small Spacy model on the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dacy.datasets.dane(splits=[\"test\"])\n",
    "\n",
    "\n",
    "def apply_model(example, nlp):\n",
    "    example.predicted = nlp(example.predicted.text)\n",
    "    return example\n",
    "\n",
    "# make an instance of apply_model using the spacy nlp\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "apply_spacy_model = partial(apply_model, nlp=nlp)"
   ]
  },
  {
   "source": [
    "Let's test how well the model performs on the original data, data where names are changed to other Danish names, and data where names are changes to names of Muslim origin. The name augmenter allows us to specify a number of naming patterns we wish to augment the names to. Defaults are `[\"fn,ln\", \"abbpunct,ln\"]`, which means names are augmented to the follow the pattern of either \"first_name last_name\" (e.g. Mette Frederiksen) or \"abbreviated_first_name last_name\" (e.g. M. Frederiksen). The patterns include \"fn\" (first name, Mette), \"ln\" (last name, Frederiksen), \"abb\" (abbreviated, M), \"abbpunct\" (abbreviated + ., M.). These patterns can be designed however you see fit. We will stick to the defaults for now. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk_name_dict = danish_names()\n",
    "muslim_name_dict = muslim_names()\n",
    "\n",
    "# Set keep_name to False to make the augmenter choose a new name from the dictionary\n",
    "#   otherwise, it would simply make the name fit the pattern (e.g. make abbreviations)\n",
    "# force_size ensures that the names are of the same length/format as the pattern.\n",
    "dk_aug = create_pers_augmenter(dk_name_dict, force_size=True, keep_name=False)\n",
    "muslim_aug = create_pers_augmenter(muslim_name_dict, force_size=True, keep_name=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_raw = score(test, apply_spacy_model, score_fn=[\"ents\"])\n",
    "scores_dk = score(test, apply_spacy_model, augmenter=dk_aug, score_fn=[\"ents\"])\n",
    "scores_muslim = score(test, apply_spacy_model, augmenter=muslim_aug, score_fn=[\"ents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     ents_p    ents_r    ents_f  ents_per_type_PER_p  ents_per_type_PER_r  \\\n",
       "0  0.719262  0.629032  0.671128             0.768421             0.811111   \n",
       "1  0.721881  0.632616  0.674308             0.766839             0.822222   \n",
       "2  0.696907  0.605735  0.648130             0.729282             0.733333   \n",
       "\n",
       "   ents_per_type_PER_f  ents_per_type_LOC_p  ents_per_type_LOC_r  \\\n",
       "0             0.789189             0.673267             0.708333   \n",
       "1             0.793566             0.660194             0.708333   \n",
       "2             0.731302             0.641509             0.708333   \n",
       "\n",
       "   ents_per_type_LOC_f  ents_per_type_MISC_p  ents_per_type_MISC_r  \\\n",
       "0             0.690355              0.680000              0.561983   \n",
       "1             0.683417              0.708333              0.561983   \n",
       "2             0.673267              0.704082              0.570248   \n",
       "\n",
       "   ents_per_type_MISC_f  ents_per_type_ORG_p  ents_per_type_ORG_r  \\\n",
       "0              0.615385              0.71134             0.428571   \n",
       "1              0.626728              0.71134             0.428571   \n",
       "2              0.630137              0.69000             0.428571   \n",
       "\n",
       "   ents_per_type_ORG_f  \n",
       "0             0.534884  \n",
       "1             0.534884  \n",
       "2             0.528736  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ents_p</th>\n      <th>ents_r</th>\n      <th>ents_f</th>\n      <th>ents_per_type_PER_p</th>\n      <th>ents_per_type_PER_r</th>\n      <th>ents_per_type_PER_f</th>\n      <th>ents_per_type_LOC_p</th>\n      <th>ents_per_type_LOC_r</th>\n      <th>ents_per_type_LOC_f</th>\n      <th>ents_per_type_MISC_p</th>\n      <th>ents_per_type_MISC_r</th>\n      <th>ents_per_type_MISC_f</th>\n      <th>ents_per_type_ORG_p</th>\n      <th>ents_per_type_ORG_r</th>\n      <th>ents_per_type_ORG_f</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.719262</td>\n      <td>0.629032</td>\n      <td>0.671128</td>\n      <td>0.768421</td>\n      <td>0.811111</td>\n      <td>0.789189</td>\n      <td>0.673267</td>\n      <td>0.708333</td>\n      <td>0.690355</td>\n      <td>0.680000</td>\n      <td>0.561983</td>\n      <td>0.615385</td>\n      <td>0.71134</td>\n      <td>0.428571</td>\n      <td>0.534884</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.721881</td>\n      <td>0.632616</td>\n      <td>0.674308</td>\n      <td>0.766839</td>\n      <td>0.822222</td>\n      <td>0.793566</td>\n      <td>0.660194</td>\n      <td>0.708333</td>\n      <td>0.683417</td>\n      <td>0.708333</td>\n      <td>0.561983</td>\n      <td>0.626728</td>\n      <td>0.71134</td>\n      <td>0.428571</td>\n      <td>0.534884</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.696907</td>\n      <td>0.605735</td>\n      <td>0.648130</td>\n      <td>0.729282</td>\n      <td>0.733333</td>\n      <td>0.731302</td>\n      <td>0.641509</td>\n      <td>0.708333</td>\n      <td>0.673267</td>\n      <td>0.704082</td>\n      <td>0.570248</td>\n      <td>0.630137</td>\n      <td>0.69000</td>\n      <td>0.428571</td>\n      <td>0.528736</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "scores = scores_raw + scores_dk + scores_muslim\n",
    "scores.to_df()"
   ]
  },
  {
   "source": [
    "Augmenting names to a Danish name which fit the pattern of either \"fn,ln\" or \"abbpunct,ln\" actually made it slightly easier for the model than the original test data. However, augmenting with muslim names made the model perform a lot worse than baseline - look at the recall for PERS!\n",
    "\n",
    "Let's see how good the model is with names that start with an abbreviation. We will set `force_size` to `False` so only the first word will be augmented. `keep_name` will be `True`, so we're ensuring that we don't change the names, but only augment the first name."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     ents_p    ents_r    ents_f  ents_per_type_PER_p  ents_per_type_PER_r  \\\n",
       "0  0.719262  0.629032  0.671128             0.768421             0.811111   \n",
       "1  0.721881  0.632616  0.674308             0.766839             0.822222   \n",
       "2  0.696907  0.605735  0.648130             0.729282             0.733333   \n",
       "3  0.705757  0.593190  0.644596             0.732558             0.700000   \n",
       "4  0.705757  0.593190  0.644596             0.732558             0.700000   \n",
       "\n",
       "   ents_per_type_PER_f  ents_per_type_LOC_p  ents_per_type_LOC_r  \\\n",
       "0             0.789189             0.673267             0.708333   \n",
       "1             0.793566             0.660194             0.708333   \n",
       "2             0.731302             0.641509             0.708333   \n",
       "3             0.715909             0.680000             0.708333   \n",
       "4             0.715909             0.680000             0.708333   \n",
       "\n",
       "   ents_per_type_LOC_f  ents_per_type_MISC_p  ents_per_type_MISC_r  \\\n",
       "0             0.690355              0.680000              0.561983   \n",
       "1             0.683417              0.708333              0.561983   \n",
       "2             0.673267              0.704082              0.570248   \n",
       "3             0.693878              0.686869              0.561983   \n",
       "4             0.693878              0.686869              0.561983   \n",
       "\n",
       "   ents_per_type_MISC_f  ents_per_type_ORG_p  ents_per_type_ORG_r  \\\n",
       "0              0.615385             0.711340             0.428571   \n",
       "1              0.626728             0.711340             0.428571   \n",
       "2              0.630137             0.690000             0.428571   \n",
       "3              0.618182             0.704082             0.428571   \n",
       "4              0.618182             0.704082             0.428571   \n",
       "\n",
       "   ents_per_type_ORG_f  \n",
       "0             0.534884  \n",
       "1             0.534884  \n",
       "2             0.528736  \n",
       "3             0.532819  \n",
       "4             0.532819  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ents_p</th>\n      <th>ents_r</th>\n      <th>ents_f</th>\n      <th>ents_per_type_PER_p</th>\n      <th>ents_per_type_PER_r</th>\n      <th>ents_per_type_PER_f</th>\n      <th>ents_per_type_LOC_p</th>\n      <th>ents_per_type_LOC_r</th>\n      <th>ents_per_type_LOC_f</th>\n      <th>ents_per_type_MISC_p</th>\n      <th>ents_per_type_MISC_r</th>\n      <th>ents_per_type_MISC_f</th>\n      <th>ents_per_type_ORG_p</th>\n      <th>ents_per_type_ORG_r</th>\n      <th>ents_per_type_ORG_f</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.719262</td>\n      <td>0.629032</td>\n      <td>0.671128</td>\n      <td>0.768421</td>\n      <td>0.811111</td>\n      <td>0.789189</td>\n      <td>0.673267</td>\n      <td>0.708333</td>\n      <td>0.690355</td>\n      <td>0.680000</td>\n      <td>0.561983</td>\n      <td>0.615385</td>\n      <td>0.711340</td>\n      <td>0.428571</td>\n      <td>0.534884</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.721881</td>\n      <td>0.632616</td>\n      <td>0.674308</td>\n      <td>0.766839</td>\n      <td>0.822222</td>\n      <td>0.793566</td>\n      <td>0.660194</td>\n      <td>0.708333</td>\n      <td>0.683417</td>\n      <td>0.708333</td>\n      <td>0.561983</td>\n      <td>0.626728</td>\n      <td>0.711340</td>\n      <td>0.428571</td>\n      <td>0.534884</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.696907</td>\n      <td>0.605735</td>\n      <td>0.648130</td>\n      <td>0.729282</td>\n      <td>0.733333</td>\n      <td>0.731302</td>\n      <td>0.641509</td>\n      <td>0.708333</td>\n      <td>0.673267</td>\n      <td>0.704082</td>\n      <td>0.570248</td>\n      <td>0.630137</td>\n      <td>0.690000</td>\n      <td>0.428571</td>\n      <td>0.528736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.705757</td>\n      <td>0.593190</td>\n      <td>0.644596</td>\n      <td>0.732558</td>\n      <td>0.700000</td>\n      <td>0.715909</td>\n      <td>0.680000</td>\n      <td>0.708333</td>\n      <td>0.693878</td>\n      <td>0.686869</td>\n      <td>0.561983</td>\n      <td>0.618182</td>\n      <td>0.704082</td>\n      <td>0.428571</td>\n      <td>0.532819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.705757</td>\n      <td>0.593190</td>\n      <td>0.644596</td>\n      <td>0.732558</td>\n      <td>0.700000</td>\n      <td>0.715909</td>\n      <td>0.680000</td>\n      <td>0.708333</td>\n      <td>0.693878</td>\n      <td>0.686869</td>\n      <td>0.561983</td>\n      <td>0.618182</td>\n      <td>0.704082</td>\n      <td>0.428571</td>\n      <td>0.532819</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "abb_aug = create_pers_augmenter(dk_name_dict, patterns=[\"abbpunct\"], force_size=False, keep_name=True)\n",
    "scores_abb = score(test, apply_spacy_model, augmenter=abb_aug, score_fn=[\"ents\"])\n",
    "scores += scores_abb\n",
    "scores.to_df()"
   ]
  },
  {
   "source": [
    "Auch, yet another drop in recall. The models does not like abbreviated names.\n",
    "\n",
    "Let's test how DaCy fares.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacy_small = dacy.load(\"da_dacy_small_tft-0.0.0\")\n",
    "dacy_medium = dacy.load(\"da_dacy_medium_tft-0.0.0\")\n",
    "dacy_large = dacy.load(\"da_dacy_large_tft-0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_augmenters(dataset, augmenters: List[Callable], apply_fn: Callable):\n",
    "\n",
    "    baseline_score = score(dataset, apply_fn=apply_fn, score_fn=[\"ents\"])\n",
    "    scores = baseline_score\n",
    "    for augmenter in augmenters:\n",
    "        scores += score(dataset, augmenter=augmenter, apply_fn=apply_fn, score_fn=[\"ents\"])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Spacy's `dont_augment` to get baseline\n",
    "augmenters = [dont_augment, dk_aug, muslim_aug, abb_aug]\n",
    "apply_small_dacy = partial(apply_model, nlp=dacy_small)\n",
    "apply_medium_dacy = partial(apply_model, nlp=dacy_medium)\n",
    "apply_large_dacy = partial(apply_model, nlp=dacy_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_small_dacy = score_augmenters(test, augmenters, apply_small_dacy)\n",
    "score_medium_dacy = score_augmenters(test, augmenters, apply_large_dacy)\n",
    "score_large_dacy = score_augmenters(test, augmenters, apply_large_dacy)\n",
    "\n",
    "# score_small_dacy = score(test, augmenter=augmenters, apply_fn=apply_small_dacy, score_fn=[\"ents\"])\n",
    "# score_medium_dacy = score(test, augmenter=augmenters, apply_fn=apply_medium_dacy, score_fn=[\"ents\"])\n",
    "# score_large_dacy = score(test, augmenter=augmenters, apply_fn=apply_large_dacy, score_fn=[\"ents\"])\n",
    "\n",
    "dacy_scores = score_small_dacy + score_medium_dacy + score_large_dacy\n",
    "dacy_score.to_df()[\"model\"] = [\"small\"] * 4 + [\"medium\"] * 4 + [\"large\"] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "As you can see, the models obtain slightly different performance with the `dk_aug` and `muslim_aug` per run. This is because names are randomly sampled each time, where some names might be easier to predict than others. To account for this, `score` includes a `k` argument which you can use to run the model `k` times for a more robust performance estimate. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Reconstruction of table from paper\n",
    "Alright, enough chat - let's test how different models fare on a battery of augmentations. \n",
    "\n",
    "First, define our augmenters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly change 5%/15% of characters to a neighbouring key\n",
    "keyboard_aug_05 = create_keyboard_augmenter(doc_level=1, char_level=0.05, keyboard=\"QWERTY_DA\")\n",
    "keyboard_aug_15 = create_keyboard_augmenter(doc_level=1, char_level=0.15, keyboard=\"QWERTY_DA\")\n",
    "# Change æ=ae, ø=oe, å=aa\n",
    "æøå_aug = create_æøå_augmenter(doc_level=1, char_level=1)\n",
    "# Lowercase text\n",
    "lower_case_aug = create_lower_casing_augmenter(level=1)\n",
    "# MAKE N_SENTS SCORE\n",
    "\n",
    "augmenters += [keyboard_aug_05, keyboard_aug_15, æøå_aug, lower_case_aug]"
   ]
  },
  {
   "source": [
    "Make a dict to store our models with names"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dacy_small' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4dee464f660b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0;34m\"spacy_medium\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"da_core_news_md\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0;34m\"spacy_large\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"da_core_news_lg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               \u001b[0;34m\"dacy_small\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdacy_small\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m               \u001b[0;34m\"dacy_medium\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdacy_medium\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0;34m\"dacy_large\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdacy_large\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dacy_small' is not defined"
     ]
    }
   ],
   "source": [
    "from danlp.models import load_bert_ner_model\n",
    "from NERDA.precooked import DA_BERT_ML\n",
    "\n",
    "danlp_bert = load_bert_ner_model()\n",
    "nerda_bert = DA_BERT_ML()\n",
    "\n",
    "model_dict = {\"spacy_small\" : spacy.load(\"da_core_news_sm\"),\n",
    "              \"spacy_medium\": spacy.load(\"da_core_news_md\"),\n",
    "              \"spacy_large\" : spacy.load(\"da_core_news_lg\"),\n",
    "              \"dacy_small\" : dacy_small,\n",
    "              \"dacy_medium\" : dacy_medium,\n",
    "              \"dacy_large\" : dacy_large,\n",
    "              \"danlp_bert\" : danlp_bert,\n",
    "              \"nerda_bert\" : nerda_bert,\n",
    "              }"
   ]
  },
  {
   "source": [
    "Using NERDA and DaNLP's BERT models require a slightly more involved apply function.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bert_model(example, bert_model):\n",
    "    doc = example.predicted\n",
    "    # uses spacy tokenization\n",
    "    tokens, labels = bert_model.predict([t.text for t in example.predicted])\n",
    "    ent = []\n",
    "    for i, t in enumerate(zip(doc, labels)):\n",
    "        token, label = t\n",
    "\n",
    "        # turn OOB labels into spans\n",
    "        if label == \"O\":\n",
    "            continue\n",
    "        iob, ent_type = label.split(\"-\")\n",
    "        if (i - 1 >= 0 and iob == \"I\" and labels[i - 1] == \"O\") or (\n",
    "            i == 0 and iob == \"I\"\n",
    "        ):\n",
    "            iob = \"B\"\n",
    "        if iob == \"B\":\n",
    "            start = i\n",
    "        if i + 1 >= len(labels) or labels[i + 1].split(\"-\")[0] != \"I\":\n",
    "            ent.append(Span(doc, start, i + 1, label=ent_type))\n",
    "    doc.set_ents(ent)\n",
    "    example.predicted = doc\n",
    "    return example\n",
    "\n",
    "    ### DaNLP's BERT model requires transformers==3.5.1 (install with pip install transformers==3.5.1 --no-deps)"
   ]
  },
  {
   "source": [
    "## Function to apply each model (+ create its partial apply fn) to each augmented augmented dataset (loop through dict and make a column with the name)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}